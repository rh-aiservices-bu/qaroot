---
apiVersion: v1
kind: ConfigMap
metadata:
  name: llama-stack-config
  namespace: qaroot-mvp
data:
  config.yaml: |
    version: "1.0"

    # Inference Provider (External LLM)
    inference:
      provider: remote::openai-compatible
      config:
        url: ${EXTERNAL_LLM_URL}
        api_key: ${EXTERNAL_LLM_API_KEY}
        model: qwen2.5-14b-instruct
        temperature: 0.7
        max_tokens: 2048

    # Embeddings Provider (Local in Llama Stack)
    embeddings:
      provider: sentence-transformers
      config:
        model: nomic-ai/nomic-embed-text-v1.5
        dimension: 768
        batch_size: 32
        device: cpu
